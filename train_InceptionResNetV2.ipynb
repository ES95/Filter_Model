{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from tensorflow.python.keras.optimizers import Adam, Nadam, SGD\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING THE ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= InceptionResNetV2(include_top=True, weights='imagenet', input_tensor=None, input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATAGEN + HYPERPARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21936 images belonging to 2 classes.\n",
      "Found 7495 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#PARAMETERS FOR TRAINING\n",
    "DATASET_PATH = 'F://0alcohol//alcohol'\n",
    "IMAGE_SIZE    = (299, 299)\n",
    "NUM_CLASSES   = 2\n",
    "BATCH_SIZE    = 1  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "FREEZE_LAYERS = 40  # freeze the first this many layers for training\n",
    "NUM_EPOCHS    = 5\n",
    "WEIGHTS_FINAL = 'inception.hdf5'\n",
    "\n",
    "#TO GENERATE DATA AND PREVENT CORRUPTED IMAGES\n",
    "def my_gen(gen):\n",
    "  while True:\n",
    "    try:\n",
    "      data, labels = next(gen)\n",
    "      yield data, labels\n",
    "    except:\n",
    "      pass\n",
    "# DATAGEN\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_datagen = ImageDataGenerator()\n",
    "valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/test',\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show class indices\n",
    "print('****************')\n",
    "for cls, idx in train_batches.class_indices.items():\n",
    "    print('Class #{} = {}'.format(idx, cls))\n",
    "print('****************')\n",
    "\n",
    "# build our classifier model based on pre-trained InceptionResnet:\n",
    "# 1. we don't include the top (fully connected) layers of InceptionResnet\n",
    "# 2. we add a DropOut layer followed by a1 Dense (fully connected)\n",
    "#    layer which generates softmax class score for each class\n",
    "# 3. we compile the final model using an Adam optimizer, with a\n",
    "#    low learning rate (since we are 'fine-tuning')\n",
    "\n",
    "net= InceptionResNetV2(include_top=True, weights='imagenet', input_tensor=None, input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
    "x = net.output\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n",
    "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "best_weights_filepath = 'inception.hdf5'\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "net_final.compile(optimizer=Adam(lr=1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    " \n",
    "# train the model\n",
    "net_final.fit_generator(my_gen  (train_batches),\n",
    "                        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "                        validation_data = my_gen(valid_batches),\n",
    "                        validation_steps = valid_batches.samples // BATCH_SIZE,\n",
    "                        callbacks=[saveBestModel, earlyStopping],\n",
    "                        epochs = NUM_EPOCHS)\n",
    "# save trained weights\n",
    "net_final.save(WEIGHTS_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 284938953621169761\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.python.keras.optimizers import Adam, Nadam, SGD\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
